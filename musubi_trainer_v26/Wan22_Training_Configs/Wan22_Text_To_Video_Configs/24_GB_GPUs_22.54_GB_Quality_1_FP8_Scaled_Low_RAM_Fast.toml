additional_parameters = ""
async_upload = false
base_weights_multiplier = 1
blocks_to_swap = 24
caching_latent_batch_size = 4
caching_latent_console_back = ""
caching_latent_console_num_images = 0
caching_latent_console_width = 80
caching_latent_debug_mode = ""
caching_latent_device = "cuda"
caching_latent_keep_cache = true
caching_latent_num_workers = 8
caching_latent_skip_existing = true
caching_teo_batch_size = 16
caching_teo_device = "cuda"
caching_teo_fp8_llm = false
caching_teo_keep_cache = true
caching_teo_num_workers = 8
caching_teo_skip_existing = true
caching_teo_text_encoder_dtype = "bfloat16"
caption_strategy = "folder_name"
clip = ""
clip_vision_dtype = "bfloat16"
compile = true
compile_backend = "inductor"
compile_cache_size_limit = 0
compile_dynamic = "auto"
compile_fullgraph = false
compile_mode = "default"
create_missing_captions = true
cuda_allow_tf32 = false
cuda_cudnn_benchmark = false
dataset_batch_size = 1
dataset_bucket_no_upscale = false
dataset_cache_directory = "cache_dir"
dataset_caption_extension = ".txt"
dataset_config = "/home/Ubuntu/apps/StableSwarmUI/Models/Lora/wan_dataset_config_20251216_214044.toml"
dataset_config_mode = "Generate from Folder Structure"
dataset_enable_bucket = false
dataset_resolution_height = 960
dataset_resolution_width = 960
ddp_gradient_as_bucket_view = false
ddp_static_graph = false
ddp_timeout = 0
debug_mode = "None"
dim_from_weights = false
disable_numpy_memmap = false
disable_prompt_enhancement = false
discrete_flow_shift = 5
dit = "/home/Ubuntu/Downloads/SECourses_Musubi_Trainer_v23/Training_Models_Wan/Wan-2.2-T2V-Low-Noise-BF16.safetensors"
dit_dtype = "bfloat16"
dit_high_noise = "/home/Ubuntu/Downloads/SECourses_Musubi_Trainer_v23/Training_Models_Wan/Wan-2.2-T2V-High-Noise-BF16.safetensors"
dynamo_backend = "no"
dynamo_mode = ""
dynamo_use_dynamic = false
dynamo_use_fullgraph = false
extra_accelerate_launch_args = ""
flash_attn = false
force_v2_1_time_embedding = false
fp8_base = true
fp8_scaled = true
fp8_t5 = false
full_bf16 = false
full_fp16 = false
generated_toml_path = "/home/Ubuntu/apps/StableSwarmUI/Models/Lora/wan_dataset_config_20251216_214044.toml"
gpu_ids = "0"
gradient_accumulation_steps = 1
gradient_checkpointing = true
gradient_checkpointing_cpu_offload = false
img_in_txt_in_offloading = false
learning_rate = 6e-5
log_config = false
log_prefix = ""
log_tracker_name = ""
log_with = ""
logging_dir = ""
logit_mean = 0
logit_std = 1
lr_decay_steps = 0
lr_scheduler = "constant"
lr_scheduler_args = []
lr_scheduler_min_lr_ratio = 0
lr_scheduler_num_cycles = 1
lr_scheduler_power = 1
lr_scheduler_timescale = 0
lr_scheduler_type = ""
lr_warmup_steps = 0
main_process_port = 0
max_data_loader_n_workers = 4
max_grad_norm = 0
max_timestep = 1000
max_train_epochs = 200
max_train_steps = 90000
mem_eff_save = true
metadata_arch = ""
metadata_author = ""
metadata_description = ""
metadata_license = ""
metadata_reso = ""
metadata_tags = ""
mixed_precision = "bf16"
mode_scale = 1.29
multi_gpu = false
network_alpha = 128
network_args = []
network_dim = 128
network_dropout = 0
network_module = "networks.lora_wan"
no_metadata = false
num_cpu_threads_per_process = 2
num_frames = 81
num_machines = 1
num_processes = 1
offload_inactive_dit = false
one_frame = false
optimizer_args = [ "scale_parameter=False", "relative_step=False", "warmup_init=False", "weight_decay=0.01",]
optimizer_type = "AdaFactor"
output_dir = "/home/Ubuntu/apps/StableSwarmUI/Models/Lora"
output_name = "Wan22_Text_To_Video_LoRA_Quality_1"
parent_folder_path = "/home/Ubuntu/Downloads/training_imgs"
persistent_data_loader_workers = true
preserve_distribution_shape = true
sage_attn = false
sample_at_first = false
sample_every_n_epochs = 0
sample_every_n_steps = 0
sample_guidance_scale = 7
sample_height = 960
sample_negative_prompt = ""
sample_num_frames = 81
sample_output_dir = ""
sample_seed = 99
sample_steps = 20
sample_width = 960
save_every_n_epochs = 20
save_every_n_steps = 0
save_state = false
save_state_on_train_end = false
save_state_to_huggingface = false
scale_weight_norms = 0
sdpa = true
seed = 99
show_timesteps = ""
sigmoid_scale = 1
split_attn = false
t5 = "/home/Ubuntu/Downloads/SECourses_Musubi_Trainer_v23/Training_Models_Wan/umt5-xxl-enc-bf16.safetensors"
task = "t2v-A14B"
text_encoder_dtype = "bfloat16"
timestep_sampling = "sigma"
training_comment = ""
training_mode = "LoRA Training"
use_pinned_memory_for_block_swap = false
vae = "/home/Ubuntu/Downloads/SECourses_Musubi_Trainer_v23/Training_Models_Wan/Wan2_1_VAE_bf16.safetensors"
vae_cache_cpu = false
vae_dtype = "bfloat16"
vae_tiling = false
wandb_run_name = ""
weighting_scheme = "none"
xformers = false
